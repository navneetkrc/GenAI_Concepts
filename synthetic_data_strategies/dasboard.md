# ğŸ” On Synthetic Data Strategies for Domain-Specific Generative Retrieval

_A Github-Optimized Dashboard for Paper Summary, Results, and Learnings.

---

# ğŸ“‘ Table of Contents
- [ğŸ“Š 1. Overview Dashboard (Executive Summary)](#-1-overview-dashboard-executive-summary)
- [ğŸ“ˆ 2. Detailed Metrics Dashboard (Performance Insights)](#-2-detailed-metrics-dashboard-performance-insights)
  - [ğŸ§ª Synthetic Query Granularity Impact](#-synthetic-query-granularity-impact)
  - [ğŸ§ª Constraints-Based Queries Impact](#-constraints-based-queries-impact)
  - [ğŸ§ª Context2ID Importance (Memorization)](#-context2id-importance-memorization)
  - [ğŸ§ª Preference Learning: Hard Negatives vs Random](#-preference-learning-hard-negatives-vs-random)
  - [ğŸ“Š Off-the-Shelf Comparisons](#-off-the-shelf-comparisons)
- [ğŸ› ï¸ 3. Behind the Scenes Dashboard (Data Generation + Training)](#ï¸-3-behind-the-scenes-dashboard-data-generation--training)
  - [ğŸ“š Two-Stage Training Pipeline (ASCII Diagram)](#-two-stage-training-pipeline-ascii-diagram)
  - [âœï¸ Synthetic Query Types](#ï¸-synthetic-query-types)
  - [ğŸ§  Context2ID vs Query2ID](#-context2id-vs-query2id)
  - [ğŸ”¥ Hard Negative Mining in Preference Learning](#-hard-negative-mining-in-preference-learning)
  - [ğŸ§  LLMs Used for Synthetic Data](#-llms-used-for-synthetic-data)
- [ğŸ“‹ 4. Final Takeaways Dashboard](#-4-final-takeaways-dashboard)
  - [âœ… Top 5 Key Learnings](#-top-5-key-learnings)
  - [ğŸš€ Future Work Ideas](#-future-work-ideas)

---

# ğŸ“Š 1. Overview Dashboard (Executive Summary)

...


---

## âœï¸ Synthetic Query Types
- **Chunk-Level Queries**: Capture document-wide facts
- **Sentence-Level Queries**: Capture fine-grained details
- **Constraints-Based Queries**: Inject metadata/domain info

---

## ğŸ§  Context2ID vs Query2ID

| Data Type | What it Trains | Purpose |
|:---------|:---------------|:--------|
| Context2ID | Memorizing document content | Enables the model to "know" the corpus |
| Query2ID | Query understanding & retrieval | Trains matching user queries to correct documents |

---

## ğŸ”¥ Hard Negative Mining in Preference Learning
- Hard negatives = **Top-ranked wrong documents**.
- Preference Optimization Loss (RPO) **favors positives** over negatives.
- Avoid random negatives â” hurts model quality!

---

## ğŸ§  LLMs Used for Synthetic Data
| Task | LLM |
|:----|:---|
| Synthetic Query Generation | Mixtral 8x7B |
| Semantic Identifier Generation | Claude 3 Sonnet |

---

# ğŸ“‹ 4. Final Takeaways Dashboard

## âœ… Top 5 Key Learnings
- **Sentence-level queries** and **multi-granularity** matter.
- **Domain-specific constraints** enhance retrieval.
- **Context memorization** boosts performance.
- **Hard negatives** are crucial for ranking learning.
- **Synthetic data training** alone can reach SOTA levels!

---

## ğŸš€ Future Work Ideas
- **Incremental updates** to models without full retraining.
- **More complex queries**: multi-hop or multi-evidence.
- **Apply strategies to dense retrieval** domain adaptation.
- **Automatic metadata extraction** to create better constraint-based queries.

---

# âœ¨ End of Dashboard

> Made for better readability and professional presentation on GitHub.  
> Customize it with your repo theme/colors if needed! ğŸ¨ğŸš€
