# ğŸ” On Synthetic Data Strategies for Domain-Specific Generative Retrieval

_A professional GitHub-friendly Dashboard Presentation_

---

# ğŸ“‘ Table of Contents
> Jump directly to any section ğŸš€

- [ğŸ“Š Overview Dashboard (Executive Summary)](#-overview-dashboard-executive-summary)
- [ğŸ“ˆ Detailed Metrics Dashboard (Performance Insights)](#-detailed-metrics-dashboard-performance-insights)
  - [ğŸ§ª Synthetic Query Granularity Impact](#-synthetic-query-granularity-impact)
  - [ğŸ§ª Constraints-Based Queries Impact](#-constraints-based-queries-impact)
  - [ğŸ§ª Context2ID Importance (Memorization)](#-context2id-importance-memorization)
  - [ğŸ§ª Preference Learning: Hard Negatives vs Random](#-preference-learning-hard-negatives-vs-random)
  - [ğŸ“Š Off-the-Shelf Comparisons](#-off-the-shelf-comparisons)
- [ğŸ› ï¸ Behind the Scenes Dashboard (Data Generation + Training)](#ï¸-behind-the-scenes-dashboard-data-generation--training)
  - [ğŸ“š Two-Stage Training Pipeline](#-two-stage-training-pipeline)
  - [âœï¸ Synthetic Query Types](#ï¸-synthetic-query-types)
  - [ğŸ§  Context2ID vs Query2ID](#-context2id-vs-query2id)
  - [ğŸ”¥ Hard Negative Mining](#-hard-negative-mining)
  - [ğŸ§  LLMs Used for Synthetic Data](#-llms-used-for-synthetic-data)
- [ğŸ“‹ Final Takeaways Dashboard](#-final-takeaways-dashboard)
  - [âœ… Top 5 Key Learnings](#-top-5-key-learnings)
  - [ğŸš€ Future Work Ideas](#-future-work-ideas)

---
# ğŸ“Š Overview Dashboard (Executive Summary)

### ğŸ“„ Paper Info
- **Title:** On Synthetic Data Strategies for Domain-Specific Generative Retrieval
- **Authors:** AWS AI + CMU
- **Goal:** Overcome annotation challenges for domain-specific retrieval by using synthetic data.

---

### ğŸ—ï¸ Two-Stage Training Pipeline

| Stage | Goal | Key Techniques |
|:------|:-----|:---------------|
| **Stage 1:** Fine-tuning | Memorization & Generalization | Context2ID + Query2ID (Multi-Granular + Constraints) |
| **Stage 2:** Preference Learning | Better Ranking | Hard Negative Mining + RPO |

---

### âœ… Key Contributions
- **Multi-Granularity** â” Detailed understanding from both chunks and sentences.
- **Domain Constraints** â” Improve domain relevance.
- **Context Memorization** â” Helps build better internal corpus knowledge.
- **Hard Negatives** â” Critical for ranking optimization.
- **Pure Synthetic Training** â” Competitive with SOTA retrieval models.

---
[ğŸ” Back to Top](#-table-of-contents)

---

# ğŸ“ˆ Detailed Metrics Dashboard (Performance Insights)

## ğŸ§ª Synthetic Query Granularity Impact

| Setting | HIT@4 | HIT@10 | MAP@10 | MRR@10 |
|:--------|:------|:-------|:-------|:------|
| Chunk-Only Queries | 43.64 | 66.65 | 13.98 | 31.14 |
| Chunk + Sentence Queries | **61.64** | **81.69** | **22.13** | **47.20** |

> ğŸ“¢ **Sentence-level queries add fine-grained strength!**

---

## ğŸ§ª Constraints-Based Queries Impact

| Dataset | Metric | w/o Constraints | w/ Constraints |
|:--------|:-------|:---------------|:-------------|
| MultiHop-RAG | HIT@4 | 61.64 | **69.98** |
| AllSides | HIT@1 | 10.19 | **14.20** |
| AGNews | HIT@1 | 59.91 | **62.19** |

> ğŸ“¢ **Domain-specific synthetic queries help a lot!**

---

## ğŸ§ª Context2ID Importance (Memorization)

| Dataset | Metric | w/o Context2ID | w/ Context2ID |
|:--------|:-------|:--------------|:------------|
| MultiHop-RAG | HIT@4 | 41.33 | **69.98** |
| Natural Questions | HIT@1 | 69.72 | **70.71** |

> ğŸ“¢ **Content memorization boosts results significantly!**

---

## ğŸ§ª Preference Learning: Hard Negatives vs Random

| Method | HIT@4 | HIT@10 | MAP@10 | MRR@10 |
|:-------|:------|:-------|:-------|:------|
| Random Negatives | 58.94 | 82.88 | 20.88 | 43.53 |
| Top-5 Hard Negatives | **71.53** | **89.62** | **26.36** | **55.40** |
| Top-10 Hard Negatives | 71.88 | 89.80 | 26.23 | 54.94 |

> ğŸ“¢ **Hard negatives > Random negatives!**

---

## ğŸ“Š Off-the-Shelf Comparisons

| Retriever | Relative Score |
|:----------|:--------------|
| BM25 | ğŸ”µ |
| bge-large-en | ğŸŸ¡ |
| Contriever-msmarco | ğŸŸ¡ |
| E5-mistral-7b | ğŸŸ¢ |
| GTE-Qwen2-7b | ğŸŸ¢ |
| **Generative Retrieval (Synthetic)** | ğŸ† |

---
[ğŸ” Back to Top](#-table-of-contents)

---

# ğŸ› ï¸ Behind the Scenes Dashboard (Data Generation + Training)

## ğŸ“š Two-Stage Training Pipeline


---

## âœï¸ Synthetic Query Types
- **Chunk-level**: Document-wide concepts
- **Sentence-level**: Fine details
- **Constraints-based**: Metadata-driven customization

---

## ğŸ§  Context2ID vs Query2ID

| Data Type | Focus | Purpose |
|:----------|:------|:--------|
| Context2ID | Raw Content | Memorization |
| Query2ID | Synthetic Query | Query-to-Doc Matching |

---

## ğŸ”¥ Hard Negative Mining
- Retrieve top wrong docs after Stage 1
- Optimize model via **RPO loss** to prefer positives
- Random negatives = âŒ bad training signal

---

## ğŸ§  LLMs Used
| Purpose | LLM |
|:--------|:----|
| Synthetic Queries | Mixtral 8x7B |
| Document Identifiers | Claude 3 Sonnet |

---
[ğŸ” Back to Top](#-table-of-contents)

---

# ğŸ“‹ Final Takeaways Dashboard

## âœ… Top 5 Key Learnings
- Sentence-level synthetic queries boost performance.
- Domain constraints make synthetic data more effective.
- Memorizing corpus content (Context2ID) is critical.
- Hard negatives drive better preference learning.
- Pure synthetic data can compete with SOTA models.

---

## ğŸš€ Future Work Ideas
- Incremental learning for new documents.
- Generate multi-hop or multi-evidence queries.
- Adapt synthetic strategies to dense retrieval.
- Automate metadata-based query generation.

---
# ğŸ¯ End of Dashboard
